{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Contents <a id='top'></a>\n",
    "\n",
    "1. <a href=#intro>Introduction</a>\n",
    "    1. <a href=#onesample>One Sample $t$-test</a>\n",
    "    1. <a href=#smoking-mums>Smoking Mums Example</a>\n",
    "1. <a href=#comp-means>Comparing Means</a>\n",
    "    1. <a href=#comp-means>Two-Sample $t$-test</a>\n",
    "    1. <a href=#fev>Forced Expiration Volume Example</a>    \n",
    "    1. <a href=#dep-samples>Dependent Samples $t$-test</a>\n",
    "    1. <a href=#more-2>Comparing More Than 2 Groups</a>\n",
    "    1. <a href=#alt-tests>When Assumptions Fail</a>\n",
    "1. <a href=#contingency-tables>Contingency Tables</a>\n",
    "1. <a href=#sim-based>Simulation-Based Inference</a>\n",
    "    1. <a href=#sim-based>Power Analysis</a>\n",
    "1. <a href=#ref>References and Links</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## 1. Introduction\n",
    "<a href=#top>(back to top)</a>\n",
    "\n",
    "In statistics, we often wish to make inference about a *population*, using a *sample*. The sample typically has uncertainty associated with it, because the precise values will differ each time we draw a sample from the population.\n",
    "\n",
    "In other situations, we might want to make comparisons between groups, and to assess if the observed differences between the groups are significant, in light of the uncertainty. This chapter presents some methods of making such assessments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the typical set-up: Suppose that there is a population, which can be represented by several fixed but unknown parameters. We take a sample of observations in order to estimate the parameters. **Hypothesis tests** allow us to assess the significance of these parameters. The acceptance or rejection of a hypothesis is typically based on the probability of observing a sample at least as extreme as the one that we did observe.\n",
    "\n",
    "Consider a specific example. Suppose we wish to estimate the **mean** height of all students within NUS. The mean is our parameter of interest. It is typically denoted with a greek letter $\\mu$. The population consists of ALL students within NUS. It is not feasible to measure the heights of every single person in the population. So we decide to select 100 students *at random* from the population, and only measure **their** heights. The 100 students form the sample. When we select them, we have to ensure that all students were equally likely to be sampled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The steps to apply a hypothesis test are:\n",
    "\n",
    "  1. Make sure you know the assumptions behind the test.\n",
    "  2. Write down the null and alternative hypotheses. The hypothesis is typically an assertion about the parameter, or the set of parameters of interest.\n",
    "  3. Compute the test statistic (from the observed data). The test statistic gives an indication of the veracity of the null hypothesis. But it alone is not enough to determine if the null hypothesis is true. We have to consider the distribution of possible test statistic values, to see if what we observed was anomalous, or in accordance with the null hypothesis.\n",
    "  4. Determine the $p$-value. If a $p$-value is small, then we can either conclude that a rare event has taken place, or that our null hypothesis was not true.\n",
    "  5. Summarise the conclusion, in the context of the data that you have.\n",
    "  \n",
    "*This is the thinking process behind a statistical hypothesis test.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='onesample'></a>\n",
    "### One-Sample $t$-Test\n",
    "\n",
    "The one-sample $t$-test is for testing the mean of a population from which we have drawn a random sample. The assumptions are that\n",
    "  * the observations are independent.\n",
    "  * the observations are from a Normal distribution with the same mean and variance.\n",
    "\n",
    "First, let's understand what we mean by a Normal distribution, a mean and a variance using simulation. Probability distributions dictate the frequency with which values occur for values from that distribution. One such probability distribution is the Normal, or Gaussian, distribution. In fact, what we have is a family of distributions, parametrised by a mean and a variance. We can make our computer generate values from Normal distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.linspace(stats.norm.ppf(0.0001), stats.norm.ppf(0.9999), 100)\n",
    "plt.plot(x, stats.norm.pdf(x), 'r-', lw = 1); plt.grid()\n",
    "plt.title(\"Probability density function of N(0,1) distribution\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randn(100, )\n",
    "#plt.hist(X); plt.grid()\n",
    "plt.hist(X, bins = 20, density = True); plt.grid()\n",
    "plt.plot(x, stats.norm.pdf(x), 'r-', lw = 1)\n",
    "plt.title(\"Histogram of N(0,1) variates\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe how the values fill up a bell-shape. Values close to 0 occur more often than values close to 3 or $-$3. This is what we mean by the (empirical) distribution of values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distributional Assumptions\n",
    "\n",
    "Let's return to our one-sample $t$-test. The null hypothesis states that the data comes from a Normal distribution with a particular mean (centre of the bell shape). We measure the evidence against $H_0$ by assessing how far out in the tails the **observed mean** was, compared to its distribution specified by the null hypothesis.\n",
    "\n",
    "The null hypothesis is usually denoted by $H_0$ and the alternative by $H_1$. If we represent the unknown mean of the population by $\\mu$, then the hypotheses can be stated as:\n",
    "\n",
    "\\begin{align}\n",
    "H_0 : \\mu = \\mu_0 \\\\\n",
    "H_1 : \\mu \\neq \\mu_0\n",
    "\\end{align}\n",
    "\n",
    "where $\\mu_0$ is a value specified by us before the data collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test statistic\n",
    "\n",
    "The test statistic is the actual number that is used to make the decision in a hypothesis test. It is computed using \n",
    "\n",
    "* the measurements in the sample, and \n",
    "* parameter values specified in the null hypothesis.\n",
    "\n",
    "The test statistic for the one sample $t$-test is \n",
    "\n",
    "$$\n",
    "T_1 = \\frac{\\bar{X} - \\mu_0}{s/\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "* $\\mu_0$ comes from the specification of the population mean in the null hypothesis.\n",
    "* $n$ is the number of observations in the sample.\n",
    "* $\\bar{X}$ is the mean and $s$ is the standard deviation of the values **in the sample,** computed from\n",
    "$$\n",
    "\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i \\qquad \\text{and} \\qquad s = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^n (X_i - \\bar{X})^2 }\n",
    "$$\n",
    "\n",
    "Large positive or negative values of $T_1$ indicate evidence against the null hypothesis, because this means that $\\bar{X}$ is very far-removed from $\\mu_0$, which we believed to be true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts0 = [stats.ttest_1samp(np.random.randn(16, ), 0)[0] for x in range(5000)]\n",
    "plt.hist(ts0, bins = 20, density = True); plt.grid()\n",
    "t = np.linspace(stats.t.ppf(0.0001, df = 15), stats.t.ppf(0.9999, df = 15), 100)\n",
    "plt.plot(t, stats.t.pdf(t, df = 15), 'r-', lw = 1)\n",
    "plt.title(\"Histogram of test statistic from 5000 samples\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(stats.t.ppf(0.0001, df = 15), stats.t.ppf(0.9999, df = 15), 100)\n",
    "plt.plot(t, stats.t.pdf(t, df = 15), 'r-', lw = 1); plt.grid()\n",
    "plt.plot(t, stats.norm.pdf(t), 'b', lw = 1, linestyle = 'dashed');  # N(0,1) pdf for comparison\n",
    "plt.title(\"Probability density function of t(15) distribution\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $p$-Value\n",
    "\n",
    "The $p$-value is the probability of obtaining the observed test statistic or a more extreme value, when $H_0$ is true. \n",
    "If this probability or $p$-value is very small, then we can conclude that:\n",
    "\n",
    "> Either an exceptionally rare (chance) event has occurred or the theory is not true.\n",
    "\n",
    "A typical value that it is compared to is 0.05 but remember that this is arbitrary in some sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='smoking-mums'></a>\n",
    "### Smoking Mums Example\n",
    "\n",
    "The file `smoking_mum_baby_wt.csv` contains the weights of 47 babies born to mothers who smoked. In this section, we shall test whether the mean weight of those babies was significantly different from 3.50 kilograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_wts = pd.read_csv('../data/smoking_mum_baby_wt.csv', header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Check Assumptions\n",
    "\n",
    "From the boxplot, it does seem as the though the median weight of babies is less than 3.5 kg. The histogram does not indicate strong skewness in the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myscripts import inference\n",
    "\n",
    "inference.check_normality(baby_wts.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another method to check Normality is to make a quantile-quantile plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quantile-quantile plot above is a visual comparison between a dataset and \n",
    "a theoretical Normal distribution. If most of the points are close to the line, we would conclude that the data is from a Normal distribution. From the plots above, we would conclude that it is reasonable to assume that the data is from a Normal distribution. The assumption holds; we can proceed to the next step of the test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Null and Alternative Hypotheses\n",
    "\n",
    "The statement of the hypotheses in this case would be \n",
    "\n",
    "\\begin{eqnarray}\n",
    "H_0 &:& \\mu = 3.50 \\\\\n",
    "H_1 &:& \\mu \\ne 3.50 \n",
    "\\end{eqnarray}\n",
    "\n",
    "Remember that null and alternative hypotheses cannot have any overlap in the regions that they specify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps 3 & 4: Compute test statistic and $p$-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ts = stats.ttest_1samp(baby_wts.x, 3.5)\n",
    "print(f'The test statistic value is {ts[0]:.3f}.')\n",
    "print(f'The corresponding p-value is {ts[1]:.3f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Conclusion from $p$-Value\n",
    "\n",
    "We would conclude that we have strong evidence against the null hypothesis and that the mean weight of babies born to smoking mothers is significantly different from 3.50 kg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='comp-means'></a>\n",
    "## 2. Comparing Means\n",
    "<a href=#top>(back to top)</a>\n",
    "\n",
    "### Two-Sample $t$-Test\n",
    "\n",
    "This test is used to assess if two groups of observations come from populations with the same mean. The assumptions for this test are that \n",
    "  * The data are independent (within each group and between the groups).\n",
    "  * The two populations have the same variance.\n",
    "  * The data are Normally distributed.\n",
    "  \n",
    "If the two groups have different variances, we have to apply the test for unequal variances. To check if the variances are equal, we can apply a heuristic rule: if the larger (sample) standard deviation is more than twice the smaller one, then use the test for unequal variances.\n",
    "\n",
    "The null and alternative hypotheses are typically stated as \n",
    "\n",
    "\\begin{align}\n",
    "H_0 : \\mu_1 = \\mu_2 \\\\\n",
    "H_1 : \\mu_1 \\neq \\mu_2\n",
    "\\end{align}\n",
    "\n",
    "If we denote the observations from group 1 as $X_1, X_2, \\ldots, X_{n_1}$ and the observations from group 2 as $Y_1, Y_2, \\ldots, Y_{n_2}$, then the formula for the test statistic is \n",
    "\n",
    "$$\n",
    "T_2 = \\frac{(\\bar{X} - \\bar{Y}) - (\\mu_1 - \\mu_2)}{s_p/\\sqrt{n_1 + n_2 -2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fev'></a>\n",
    "### Forced Expiration Volume Example\n",
    "\n",
    "Forced Expiration Volume (FEV) is an index of pulmonary function, that measures the volume of air expelled after 1 second of constant effort. The dataset `fev.csv` contains measurements on 654 children in 1980. \n",
    "\n",
    "In the dataset, 0 represents a female and 1 represents a male. Similarly, in the smoking column, 0 represents a non-smoker and 1 represents a smoker.\n",
    "\n",
    "Let us perform a two-sample $t$-test to assess if the mean FEV for males is different from mean FEV for females."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fev = pd.read_csv('../data/fev.csv', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference.check_normality(fev.fev[fev.Sex == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference.check_normality(fev.fev[fev.Sex == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fev.groupby('Sex').fev.describe().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it is reasonable to assume equal variance between the two populations, the assumption of Normality for the second group is suspect. Specifically, we can see that the sample distribution is quite right-skewed. \n",
    "\n",
    "Still, we can proceed with the two-sample $t$-test with equal variances; $t$-tests are generally robust to mild violations of their assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts2 = stats.ttest_ind(fev.fev[fev.Sex == 0], fev.fev[fev.Sex == 1])\n",
    "print(f'The test statistic value is {ts2[0]:.3f}.')\n",
    "print(f'The corresponding p-value is {ts2[1]:.3f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stats.ttest_ind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(fev.fev[fev.Sex == 0], fev.fev[fev.Sex == 1], equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dep-samples'></a>\n",
    "### Dependent Samples $t$-Test\n",
    "\n",
    "Sometimes, when we have two \"groups\", it is possible to match each observation in one group with exactly one observation in the other group. In such cases, the dependent samples $t$-test is appropriate, not the two-sample $t$-test. \n",
    "\n",
    "For instance, consider the following studies:\n",
    "* A group of anorexic girls' weights was measured before and after a treatment for anorexia.\n",
    "* A group of hypertensive patients' blood pressure was measured before and after a month of treatment by medication.\n",
    "\n",
    "We let $X_1, X_2, \\ldots, X_n$ be the measurements before the therapy (group 1), and let $Y_1, Y_2, \\ldots, Y_n$ be the measurements after the therapy (group 2). To analyse dependent data, we construct a new variable \n",
    "$$\n",
    "D_i = X_i - Y_i\n",
    "$$\n",
    "\n",
    "If we represent $\\mu_D$ as the population mean of the difference in measurements, then testing \n",
    "$$\n",
    "H_0 : \\mu_D = 0\n",
    "$$\n",
    "is equivalent to testing $H_0 : \\mu_1 = \\mu_2$.\n",
    "\n",
    "The rest of the procedure is exactly similar to just the application of the one-sample $t$-test to the dataset of differences.\n",
    "\n",
    "### Dependent Samples Example\n",
    "\n",
    "A study was conducted on a sample of 10 patients with kidney disease. After measuring their protein level, they were all treated with a new drug over an 8-week period. The level of protein in their urine was then measured once more.\n",
    "\n",
    "It is of interest to determine if the amount of protein in the urine has changed significantly, indicating that the drug has an effect. The data is contained in the file `urine.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renal = pd.read_csv('../data/urine.csv', header = 0)\n",
    "t3 = stats.ttest_rel(renal.before, renal.after)\n",
    "\n",
    "print(f'The test statistic value is {t3[0]:.3f}.')\n",
    "print(f'The corresponding p-value is {t3[1]:.3f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='more-2'></a>\n",
    "### Comparing More Than 2 Groups\n",
    "<a href=#top>(back to top)</a>\n",
    "\n",
    "When we have more than two groups, we use a generalisation of the two-sample $t$-test. The method is known as ANOVA, which stands for ANalysis Of VAriance. Essentially, we are comparing the variance within groups to the variability between groups. If the latter is large compared to the former, then we have reason to believe that the group means are different. On the other hand, if the variability within the group appears to dominate, then we have too much uncertainty and cannot conclude that the means of the groups are different.\n",
    "\n",
    "The assumptions of this test are:\n",
    "  * The observations from each group are from a Normal distribution.\n",
    "  * The variance within each group is the same.\n",
    "  * The data are independent (within each group and between the groups).\n",
    "  \n",
    "If there are $k$ groups, then the null hypothesis can be stated as\n",
    "$$\n",
    "H_0 : \\mu_1 = \\mu_2 = \\cdots = \\mu_k\n",
    "$$\n",
    "\n",
    "The alternative hypothesis is best stated in words:\n",
    "$$\n",
    "H_1 : \\text{At least two of group means are different}\n",
    "$$\n",
    "\n",
    "The intuitive test statistic is given by the following formula:\n",
    "$$\n",
    "\\frac{\\text{Variability between groups}}{\\text{Variability within groups}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA Example\n",
    "\n",
    "Four different concentrations of fertiliser have been used on a particular plant species. Each concentration is applied to 5 randomly selected plants, and their growth is measured after 2 weeks. In addition, there was a control group, where no fertiliser was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "growth = pd.read_csv('../data/growth.csv', header = 0)\n",
    "growth.conc_levels.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data consists of 5 readings from five separate groups. The function for the one-way test requires the readings from each group to be in the form of a list, so we use the following list code to split the data apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = [growth.growth[growth.conc_levels == ll] for ll in growth.conc_levels.unique()]\n",
    "# Easier, since data is ordered:\n",
    "x2 = growth.growth.to_numpy().reshape(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(x2.T, showmeans = True); ax.grid()\n",
    "ax.set_xticklabels(growth.conc_levels.unique());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.boxplot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the test, we call the following function, which returns a tuple as usual, containing the test-statistic and the $p$-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_obs = stats.f_oneway(*x2)\n",
    "# Alternative, more explicit code:\n",
    "# stats.f_oneway(x2[0], x2[1], x2[2], x2[3], x2[4])\n",
    "print(f'The test statistic value is {f_obs[0]:.3f}.')\n",
    "print(f'The corresponding p-value is {f_obs[1]:.3f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $p$-value is extremely small, but we need to check the assumptions. The key assumption is that the residuals are normally distributed. This function does not return us the residuals, so we compute them ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "growth.head(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "growth.groupby('conc_levels')['growth'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = growth.groupby('conc_levels')['growth'].apply(lambda x: x - np.mean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1_index = res1.index.droplevel(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1_values = res1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#growth['res1'] = growth.groupby('conc_levels')['growth'].apply(lambda x: x - np.mean(x))\n",
    "growth['res1'] = pd.Series(res1.values, res1.index.droplevel(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the variances, we use the usual `describe()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "growth.groupby('conc_levels').res1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference.check_normality(growth.res1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There does seem to be an unusual spike in the central bin of the histogram, but the tails of the distribution seem alright.\n",
    "\n",
    "More fundamentally, notice what we have done here: we haven't plotted the sample distribution of each concentration level separately to check for normality. Instead, we have plotted the \"aggregate\" sample distribution, which looks normal enough for us to apply ANOVA. This is a heuristic that is reliable in practice. However, there are other solutions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='alt-tests'></a>\n",
    "### When Assumptions Fail\n",
    "<a href=#top>(back to top)</a>\n",
    "\n",
    "When one or more of the assumptions fail, we can do one or more of the following:\n",
    "\n",
    "1. If the residuals appear to be skewed, we can apply a transformation, such as the log or square-root, to make them symmetric.\n",
    "2. If we do not wish to do that, we may turn to non-parametric versions of these tests. Non-parametric tests such as the Wilcoxon signed-rank test and the Kruskal Wallis test are based on ranks of the observations, not their actual values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='contingency-tables'></a>\n",
    "## 3. Contingency Tables (Categorical Variables)\n",
    "<a href=#top>(back to top)</a>\n",
    "\n",
    "Suppose that 1,073 patients at NUH were sampled, for a study where the onset of severe chest pain in patients at high risk for cardio-vascular disease (CVD) is recorded for each subject. The 1,073 patients were queried on two aspects:\n",
    "\n",
    "* Have they experienced the onset of severe chest pain in the preceding 6 months? (yes/no)\n",
    "* Gender? (male/female)\n",
    "\n",
    "Here is what the tabulated data look like:\n",
    "\n",
    "|       | Chest Pain| No Chest Pain| Total|\n",
    "|:------|----------:|-------------:|-----:|\n",
    "|Male   |         46|           474|   520|\n",
    "|Female |         37|           516|   553|\n",
    "|Total  |         83|           990|  1073|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two categorical variables are gender and the presence/abscence of chest pain. We can compute conditional proportions (in percentage form) in the table for the preceding example.\n",
    "\n",
    "|       | Chest Pain| No Chest Pain|\n",
    "|:------|----------:|-------------:|\n",
    "|Male   |       8.85|         91.15|\n",
    "|Female |       6.69|         93.31|\n",
    "\n",
    "8.85% is a point estimate of $P(\\mbox{chest pain} | \\mbox{male})$. Similarly, 6.7\\% is a point estimate of \n",
    "$P(\\mbox{chest pain} |\\mbox{female})$.\n",
    "\n",
    "We are interested in knowing if the population quantities are equal. If they are not equal, we say that there is an association between gender and chest pain. If they are equal, we say that there is no association, or that the two variables are independent.\n",
    "\n",
    "What we are testing in this section is whether or not \n",
    "$$\n",
    "P(\\mbox{chest pain} | \\mbox{male}) = \n",
    "P(\\mbox{chest pain} |\\mbox{female})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $\\chi^2$-test of independence will have the following hypotheses:\n",
    "\\begin{align}\n",
    "& H_0 : \\text{The two variables are independent} \\\\\n",
    "& H_1 : \\text{The two variables are dependent}\n",
    "\\end{align}\n",
    "\n",
    "In order to compute the test statistic, we shall have to compute the expected cell counts, under independence, and compare them to the observed cell counts.\n",
    "\n",
    "For a particular cell in the table, the *expected cell count* is \n",
    "$$\n",
    "\\mbox{Expected cell count} = \\frac{\\mbox{Row total} \\times \\mbox{Column\n",
    "total}}{\\mbox{Total sample size}}\n",
    "$$\n",
    "It is what we should expect if the categorical variables were independent, but the row and column totals were the same as the observed ones.\n",
    "\n",
    "The test statistic is (just like in the comparing means case) a scaled version of the \"distance\" between observed and expected values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chest_pain = np.array([[46, 474], [37, 516]])\n",
    "#chest_pain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2, p, dof, exp = stats.chi2_contingency(chest_pain, correction = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected cell counts are automatically computed and returned to us. We can inspect them in the following manner. Notice that the expected counts are **not** integers. They are real numbers.\n",
    "\n",
    "In order to apply this test, we need to have all expected cell counts greater than 5. If this does not hold, we have to turn to Fisher's Exact Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(exp, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the $p$-value, we find that it is approximately 0.23. This is not extremely small. Hence we say that we do not have strong evidence against the null hypothesis; the two variables are not associated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To quantify the association, we can describe it in the following ways. \n",
    "\n",
    "### Difference in proportion\n",
    "\n",
    "The difference in proportion could take values between $-$1 and 1. A value close to 0 denotes that the two proportions are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_hats = chest_pain[:, 0] / np.sum(chest_pain, axis = 1)\n",
    "print(f'The difference in proportions is {np.ptp(p_hats):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risk Ratio\n",
    "\n",
    "Using the risk ratio is preferrable when the proportions for both groups is close to 0, ot both are close to 1. The risk ratio takes on values between 0 and infinity. A value close to 1 denotes that the proportions are similar to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The proportion of CVD for women is {p_hats[1] / p_hats[0]:.2f}',\n",
    "      'times the proportion of CVD for men.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fisher's Exact Test\n",
    "\n",
    "If any of the *expected cell counts* are less than 5, we have two options:\n",
    "\n",
    "1. If both variables aren't binary, i.e. if the contingency table is bigger than 2-by-2, combine cell counts so that the expected values exceed the threshold of 5. (Why do you think we can't combine in the binary case?)\n",
    "2. Perform Fisher's Exact Test\n",
    "\n",
    "In the dataset above, the expected cell counts are all above 5, but let us perform the Exact Test and see if there is a great difference in results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_out = stats.fisher_exact(chest_pain)\n",
    "print(f'The odds ratio is {fish_out[0]:.3f}, and the p-value is {fish_out[1]:.3f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $p$-value is very similar: 0.21. In smaller sample sizes, the results may be quite different; in those cases, we should use the Fisher's Test result, as it does not make distributional assumptions on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sim-based'></a>\n",
    "## 4. Simulation-Based Inference\n",
    "<a href=#top>(back to top)</a>\n",
    "### Power Analysis\n",
    "\n",
    "Let us revisit the two-sample $t$-test. This was the general form:\n",
    "\\begin{align}\n",
    "H_0 : \\mu_1 = \\mu_2 \\\\\n",
    "H_1 : \\mu_1 \\neq \\mu_2\n",
    "\\end{align}\n",
    "\n",
    "Instead of using the $p$-value alone to assess the strength of evidence against the null hypothesis, an alternative method is to specify a **significance level** and then compare the $p$-value to it. If the $p$-value from our data is smaller than the chosen significance level, we reject $H_0$. (*Historically, the values 0.05 and 0.01 have been used, but you should really think about what is relevant for your decision.*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns the four possible outcomes of a test:\n",
    "  * $H_0$ was true, but we rejected it (*Type I error*).\n",
    "  * $H_0$ was true, and we did not reject it (*not an error*).\n",
    "  * $H_0$ was false, and we rejected it (*not an error*).\n",
    "  * $H_0$ was false, but we did not reject it (*Type II error*).\n",
    "  \n",
    "We would like the probabilities of Type I and II errors to be small.\n",
    "\n",
    "The probability of the Type I error is controlled by the choice of significance level. If we choose the level to be 0.05, it means that the probability of the Type I error is 0.05.\n",
    "\n",
    "1 minus the probability of the Type II error is known as the **power of a test**.  The probability of the Type II error, and thus the power, depends on the specific alternative hypothesis. In the above case, it depends on the true value of $d = \\mu_1 - \\mu_2$. \n",
    "\n",
    "These ideas can be used to guide us when computing the sample size for a test. Let's think about this for a minute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we wish to perform some simple A/B testing: We have two groups, and we wish to be able to detect a significant difference. \n",
    "\n",
    ">What sample size should I use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question is actually a little more complex than that. Let's think about what we need to consider. The answers to these questions are intuitive, but if you put them in the context of the test statistic for two-sample $t$-tests, you will find they make formal sense too.\n",
    "\n",
    "$$\n",
    "T_2 = \\frac{(\\bar{X} - \\bar{Y}) - (\\mu_1 - \\mu_2)}{s_p/\\sqrt{n_1 + n_2 -2}}\n",
    "$$\n",
    "\n",
    "  * How does the true difference between the groups affect the sample size that I need?\n",
    "      * If the true difference is large, I don't need such a large sample from each group.\n",
    "  * How does the variability within each group affect my sample size?\n",
    "      * If the variability is small, I don't need a large sample size. Imagine if there was no variability in each group...\n",
    "  * How does the significance level affect the sample size I need? Recall that the significance level determines my Type I error probability.\n",
    "      * A smaller significance level means I wish to be more confident of my result - I would need a larger sample size.\n",
    "\n",
    "Suppose now, that we fix the significance level to be 0.05, with a desired power of at least 0.9 and we are interested in detecting a difference between the means of 1, when the standard deviation of observed values is 1.2. What sample size do I need?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, we are going to simulate running the experiment several times. To be precise:\n",
    "\n",
    "1. Generate a set of values for each group with some sample size $n$ in each group. The mean for group A could be 0, and the mean for group B 1.0. The standard deviation within each group will be 1.2.\n",
    "2. Carry out the hypothesis test at significance level 0.05.\n",
    "3. If we reject, we count it as a correct result.\n",
    "\n",
    "Repeat steps 1&ndash;3 several times with the same $n$. The proportion \n",
    "of times we reject the null hypothesis is an estimate of the power \n",
    "of our test. We want this to be at least 0.9.\n",
    "\n",
    "Now we vary $n$ and repeat the entire procedure. This gives us an estimate of power at various $n$. Then we pick the smallest $n$ that yields a power more than 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time inference.estimate_power(1, 1.2, 40, nsim = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vals = np.arange(5, 50, step = 4)\n",
    "\n",
    "power_est = []\n",
    "for n_ in n_vals:\n",
    "    power_est.append(inference.estimate_power(1, 1.2, n_))\n",
    "    print(\"Done with sample size \" + str(n_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.plot(n_vals, power_est, 'go-')\n",
    "plt.hlines(0.9, n_vals[0], n_vals[-1], colors = 'b', linestyles = 'dotted')\n",
    "plt.title('Power Estimates'); plt.grid(axis = 'x'); plt.xlabel('Sample size');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, a sample size of about 32 allows a test of sufficient power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would you modify this simulation if you can only have a sample size of 25, say, and you want to find the smallest $d$ that yields a power more than 0.9?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to perform **exact** power calculations for the two-sample $t$-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.stats.power as pwr\n",
    "\n",
    "power_sm = np.array([pwr.tt_ind_solve_power(1/1.2, n_, 0.05) for n_ in np.arange(5, 50)])\n",
    "plt.plot(np.arange(5, 50), power_sm, 'go-')\n",
    "plt.hlines(0.9, 5, 49, colors = 'b', linestyles = 'dotted')\n",
    "plt.title('Exact Power'); plt.grid(axis = 'x'); plt.xlabel('Sample size');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where((power_sm >= 0.9) == True)[0][0] + 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ref'></a>\n",
    "## 5. References and Links\n",
    "<a href=#top>(back to top)</a>\n",
    "\n",
    "1. [Python for Data Science (Inferential statistics)](https://www.pythonfordatascience.org/home)\n",
    "1. [SciPy Statistical Tests](https://docs.scipy.org/doc/scipy/reference/stats.html#statistical-tests)\n",
    "1. [statsmodels Statistics (`stats`) module](https://www.statsmodels.org/stable/stats.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
